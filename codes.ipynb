{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.783704360389\n",
      "0.769194455335\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "import numpy\n",
    "import math\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "names = [\"age\", \"workclass\", \"fnlwgt\", \"education\", \"education_num\", \"marital_status\", \n",
    "         \"occupation\", \"relationship\", \"race\", \"sex\", \"capital_gain\", \"capital_loss\", \n",
    "         \"hours_per_week\", \"native_country\", \"high_income\"]\n",
    "\n",
    "income = pandas.read_csv(\"income.csv\", header=None, index_col=False, names=names)\n",
    "# Convert the categorical variables in our dataset to numeric variables\n",
    "# We can use the Categorical.from_array method from Pandas to perform the conversion to numbers\n",
    "convert_list = ['workclass', 'education', 'marital_status', 'occupation', 'relationship', \n",
    "                'race', 'sex', 'native_country', 'high_income']\n",
    "for column in convert_list:\n",
    "    col = pandas.Categorical.from_array(income[column])\n",
    "    income[column] = col.codes\n",
    "\n",
    "columns = [\"age\", \"workclass\", \"education_num\", \"marital_status\", \"occupation\", \"relationship\",\n",
    "           \"race\", \"sex\", \"hours_per_week\", \"native_country\"]\n",
    "\n",
    "income = income.reindex(numpy.random.permutation(income.index))\n",
    "\n",
    "train_max_row = math.floor(income.shape[0] * .8)\n",
    "train = income.iloc[:train_max_row]\n",
    "test = income.iloc[train_max_row:]\n",
    "\n",
    "clf = DecisionTreeClassifier(random_state=1, min_samples_leaf=75)\n",
    "clf.fit(train[columns], train[\"high_income\"])\n",
    "\n",
    "clf2 = DecisionTreeClassifier(random_state=1, max_depth=6)\n",
    "clf2.fit(train[columns], train[\"high_income\"])\n",
    "\n",
    "predict_1 = clf.predict(test[columns])\n",
    "auc_1 = roc_auc_score(predict_1, test['high_income'])\n",
    "\n",
    "predict_2 = clf2.predict(test[columns])\n",
    "auc_2 = roc_auc_score(predict_2, test['high_income'])\n",
    "\n",
    "print(auc_1)\n",
    "print(auc_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Combining predictions\n",
    "predictions = clf.predict_proba(test[columns])[:,1]\n",
    "predictions2 = clf2.predict_proba(test[columns])[:,1]\n",
    "\n",
    "auc = roc_auc_score(numpy.round((predictions + predictions2) / 2), test['high_income'])\n",
    "print(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.786035938388\n"
     ]
    }
   ],
   "source": [
    "# We'll build 10 trees using Bagging techniques\n",
    "tree_count = 10\n",
    "\n",
    "# Each \"bag\" will have 60% of the number of original rows.\n",
    "bag_proportion = .6\n",
    "\n",
    "predictions = []\n",
    "for i in range(tree_count):\n",
    "    # We select 60% of the rows from train, sampling with replacement.\n",
    "    # We set a random state to ensure we'll be able to replicate our results.\n",
    "    # We set it to i instead of a fixed value so we don't get the same sample every loop.\n",
    "    # That would make all of our trees the same.\n",
    "    bag = train.sample(frac=bag_proportion, replace=True, random_state=i)\n",
    "    # print(bag.head())\n",
    "    \n",
    "    # Fit a decision tree model to the \"bag\".\n",
    "    clf = DecisionTreeClassifier(random_state=1, min_samples_leaf=75)\n",
    "    clf.fit(bag[columns], bag[\"high_income\"])\n",
    "    \n",
    "    # Using the model, make predictions on the test data.\n",
    "    predictions.append(clf.predict_proba(test[columns])[:,1])\n",
    "\n",
    "rounded = numpy.round(sum(predictions)/len(predictions))\n",
    "auc = roc_auc_score(rounded, test['high_income'])\n",
    "print(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_entropy(column):\n",
    "    # Calculate entropy given a pandas Series, list, or numpy array.\n",
    "    counts = numpy.bincount(column)\n",
    "    probabilities = counts / len(column)\n",
    "    \n",
    "    entropy = 0\n",
    "    for prob in probabilities:\n",
    "        if prob > 0: \n",
    "            entropy += prob * math.log(prob, 2)\n",
    "    return -entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_information_gain(data_set, split_name, target_name):\n",
    "    # Calculate information gain given a dataset, column to split on, and target.\n",
    "    median = numpy.median(data_set[split_name])\n",
    "    left_split = data_set[data_set[split_name] <= median]\n",
    "    right_split = data_set[data_set[split_name] > median]\n",
    "    \n",
    "    left_entropy = calc_entropy(left_split[target_name])\n",
    "    right_entropy = calc_entropy(right_split[target_name])\n",
    "    total_entropy = calc_entropy(data_set[target_name])\n",
    "    \n",
    "    information_gain = total_entropy - (len(left_split) / len(data_set) * left_entropy +\n",
    "                                       len(right_split) / len(data_set) * right_entropy)\n",
    "    return information_gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use 1\n",
      "use 1\n",
      "use 1\n",
      "use 1\n",
      "use 1\n",
      "{'median': 4.5, 'number': 1, 'column': 'employment', 'left': {'median': 25.0, 'number': 2, 'column': 'age', 'left': {'median': 22.5, 'number': 3, 'column': 'age', 'left': {'number': 4, 'label': 0}, 'right': {'number': 5, 'label': 1}}, 'right': {'number': 6, 'label': 0}}, 'right': {'median': 40.0, 'number': 7, 'column': 'age', 'left': {'median': 37.5, 'number': 8, 'column': 'age', 'left': {'number': 9, 'label': 1}, 'right': {'number': 10, 'label': 0}}, 'right': {'number': 11, 'label': 1}}}\n",
      "use 2\n",
      "use 2\n",
      "use 2\n",
      "use 2\n",
      "use 2\n",
      "{'median': 37.5, 'number': 12, 'column': 'age', 'left': {'median': 4.0, 'number': 13, 'column': 'employment', 'left': {'median': 22.5, 'number': 14, 'column': 'age', 'left': {'number': 15, 'label': 0}, 'right': {'number': 16, 'label': 1}}, 'right': {'number': 17, 'label': 1}}, 'right': {'median': 55.0, 'number': 18, 'column': 'age', 'left': {'median': 47.5, 'number': 19, 'column': 'age', 'left': {'number': 20, 'label': 0}, 'right': {'number': 21, 'label': 1}}, 'right': {'number': 22, 'label': 0}}}\n"
     ]
    }
   ],
   "source": [
    "# Select random features\n",
    "data = pandas.DataFrame([\n",
    "    [0,4,20,0],\n",
    "    [0,4,60,2],\n",
    "    [0,5,40,1],\n",
    "    [1,4,25,1],\n",
    "    [1,5,35,2],\n",
    "    [1,5,55,1]\n",
    "    ])\n",
    "data.columns = [\"high_income\", \"employment\", \"age\", \"marital_status\"]\n",
    "\n",
    "# Set a random seed to make results reproducible.\n",
    "numpy.random.seed(1)\n",
    "\n",
    "# The dictionary to store our tree.\n",
    "tree = {}\n",
    "nodes = []\n",
    "\n",
    "# The function to find the column to split on.\n",
    "def find_best_column(data, target_name, columns):\n",
    "    information_gains = []\n",
    "    \n",
    "    # Insert your code here.\n",
    "    \n",
    "    for col in columns:\n",
    "        information_gain = calc_information_gain(data, col, \"high_income\")\n",
    "        information_gains.append(information_gain)\n",
    "\n",
    "    # Find the name of the column with the highest gain.\n",
    "    highest_gain_index = information_gains.index(max(information_gains))\n",
    "    highest_gain = columns[highest_gain_index]\n",
    "    print('use 1')\n",
    "    return highest_gain\n",
    "\n",
    "# The function to construct an id3 decision tree.\n",
    "def id3(data, target, columns, tree):\n",
    "    unique_targets = pandas.unique(data[target])\n",
    "    nodes.append(len(nodes) + 1)\n",
    "    tree[\"number\"] = nodes[-1]\n",
    "\n",
    "    if len(unique_targets) == 1:\n",
    "        if 0 in unique_targets:\n",
    "            tree[\"label\"] = 0\n",
    "        elif 1 in unique_targets:\n",
    "            tree[\"label\"] = 1\n",
    "        return\n",
    "    \n",
    "    best_column = find_best_column(data, target, columns)\n",
    "    column_median = data[best_column].median()\n",
    "    \n",
    "    tree[\"column\"] = best_column\n",
    "    tree[\"median\"] = column_median\n",
    "    \n",
    "    left_split = data[data[best_column] <= column_median]\n",
    "    right_split = data[data[best_column] > column_median]\n",
    "    split_dict = [[\"left\", left_split], [\"right\", right_split]]\n",
    "    \n",
    "    for name, split in split_dict:\n",
    "        tree[name] = {}\n",
    "        id3(split, target, columns, tree[name])\n",
    "\n",
    "\n",
    "# Run the id3 algorithm on our dataset and print the resulting tree.\n",
    "id3(data, \"high_income\", [\"employment\", \"age\", \"marital_status\"], tree)\n",
    "print(tree)\n",
    "\n",
    "def find_best_column(data, target_name, columns):\n",
    "    information_gains = []\n",
    "    \n",
    "    # Select two columns randomly.\n",
    "    cols = numpy.random.choice(columns, 2)\n",
    "    \n",
    "    for col in cols:\n",
    "        information_gain = calc_information_gain(data, col, \"high_income\")\n",
    "        information_gains.append(information_gain)\n",
    "\n",
    "    highest_gain_index = information_gains.index(max(information_gains))\n",
    "    \n",
    "    # Get the highest gain by indexing cols.\n",
    "    highest_gain = cols[highest_gain_index]\n",
    "    print('use 2')\n",
    "    \n",
    "    return highest_gain\n",
    "\n",
    "id3(data, \"high_income\", [\"employment\", \"age\", \"marital_status\"], tree)\n",
    "print(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.790173125318\n"
     ]
    }
   ],
   "source": [
    "# We'll build 10 trees\n",
    "tree_count = 10\n",
    "\n",
    "# Each \"bag\" will have 70% of the number of original rows.\n",
    "bag_proportion = .7\n",
    "\n",
    "predictions = []\n",
    "for i in range(tree_count):\n",
    "    # We select 70% of the rows from train, sampling with replacement.\n",
    "    # We set a random state to ensure we'll be able to replicate our results.\n",
    "    # We set it to i instead of a fixed value so we don't get the same sample every time.\n",
    "    bag = train.sample(frac=bag_proportion, replace=True, random_state=i)\n",
    "    \n",
    "    # Fit a decision tree model to the \"bag\".\n",
    "    clf = DecisionTreeClassifier(random_state=1, min_samples_leaf=75, splitter='random', max_features='auto')\n",
    "    clf.fit(bag[columns], bag[\"high_income\"])\n",
    "    \n",
    "    # Using the model, make predictions on the test data.\n",
    "    predictions.append(clf.predict_proba(test[columns])[:,1])\n",
    "\n",
    "combined = numpy.sum(predictions, axis=0) / 10\n",
    "rounded = numpy.round(combined)\n",
    "\n",
    "print(roc_auc_score(rounded, test[\"high_income\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.793710361957\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=150, random_state=1, min_samples_leaf=75)\n",
    "\n",
    "clf.fit(train[columns], train[\"high_income\"])\n",
    "\n",
    "predictions = clf.predict(test[columns])\n",
    "print(roc_auc_score(predictions, test[\"high_income\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.787570229992\n",
      "0.783704360389\n",
      "0.793864388775\n",
      "0.793710361957\n"
     ]
    }
   ],
   "source": [
    "# Random forests overfit less than decision trees\n",
    "clf = DecisionTreeClassifier(random_state=1, min_samples_leaf=75)\n",
    "\n",
    "clf.fit(train[columns], train[\"high_income\"])\n",
    "\n",
    "predictions = clf.predict(train[columns])\n",
    "print(roc_auc_score(predictions, train[\"high_income\"]))\n",
    "\n",
    "predictions = clf.predict(test[columns])\n",
    "print(roc_auc_score(predictions, test[\"high_income\"]))\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=150, random_state=1, min_samples_leaf=75)\n",
    "\n",
    "clf.fit(train[columns], train['high_income'])\n",
    "\n",
    "predictions_train = clf.predict(train[columns])\n",
    "print(roc_auc_score(predictions_train, train['high_income']))\n",
    "\n",
    "predictions_test = clf.predict(test[columns])\n",
    "print(roc_auc_score(predictions_test, test['high_income']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
